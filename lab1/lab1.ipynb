{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.utils import shuffle\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据集\n",
    "data = pd.read_csv('dataset.csv')\n",
    "\n",
    "# 随机排序数据集\n",
    "data = shuffle(data)\n",
    "\n",
    "# 划分特征和标签\n",
    "X = data[['data1', 'data2']].values\n",
    "y = data['label'].values\n",
    "y = y-1\n",
    "\n",
    "#数据集分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "X_train = torch.tensor(X_train,dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test,dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train,dtype=torch.long)\n",
    "y_test = torch.tensor(y_test,dtype=torch.long)\n",
    "\n",
    "y_train = F.one_hot(y_train)\n",
    "y_test = F.one_hot(y_test)\n",
    "_, y_test_labels = torch.max(y_test, 1)\n",
    "\n",
    "# 创建TensorDataset和DataLoader用于批量训练\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(2, 64)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(32, 4)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.fc3(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "# 初始化模型\n",
    "model = MLP()\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(),momentum=0.9, lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/150], Train_Loss: 1.3495, Test_Loss: 1.3639, Test Accuracy: 0.53\n",
      "Epoch [2/150], Train_Loss: 1.3254, Test_Loss: 1.3396, Test Accuracy: 0.68\n",
      "Epoch [3/150], Train_Loss: 1.3379, Test_Loss: 1.3119, Test Accuracy: 0.62\n",
      "Epoch [4/150], Train_Loss: 1.2342, Test_Loss: 1.2811, Test Accuracy: 0.55\n",
      "Epoch [5/150], Train_Loss: 1.2412, Test_Loss: 1.2499, Test Accuracy: 0.52\n",
      "Epoch [6/150], Train_Loss: 1.2413, Test_Loss: 1.2221, Test Accuracy: 0.52\n",
      "Epoch [7/150], Train_Loss: 1.2438, Test_Loss: 1.1992, Test Accuracy: 0.54\n",
      "Epoch [8/150], Train_Loss: 1.2331, Test_Loss: 1.1811, Test Accuracy: 0.57\n",
      "Epoch [9/150], Train_Loss: 1.1196, Test_Loss: 1.1670, Test Accuracy: 0.61\n",
      "Epoch [10/150], Train_Loss: 1.0633, Test_Loss: 1.1558, Test Accuracy: 0.64\n",
      "Epoch [11/150], Train_Loss: 1.1669, Test_Loss: 1.1466, Test Accuracy: 0.68\n",
      "Epoch [12/150], Train_Loss: 1.0735, Test_Loss: 1.1386, Test Accuracy: 0.70\n",
      "Epoch [13/150], Train_Loss: 1.0956, Test_Loss: 1.1313, Test Accuracy: 0.71\n",
      "Epoch [14/150], Train_Loss: 1.1730, Test_Loss: 1.1244, Test Accuracy: 0.72\n",
      "Epoch [15/150], Train_Loss: 1.0663, Test_Loss: 1.1176, Test Accuracy: 0.72\n",
      "Epoch [16/150], Train_Loss: 1.0932, Test_Loss: 1.1113, Test Accuracy: 0.72\n",
      "Epoch [17/150], Train_Loss: 1.0969, Test_Loss: 1.1049, Test Accuracy: 0.72\n",
      "Epoch [18/150], Train_Loss: 1.0319, Test_Loss: 1.0983, Test Accuracy: 0.72\n",
      "Epoch [19/150], Train_Loss: 1.0898, Test_Loss: 1.0918, Test Accuracy: 0.73\n",
      "Epoch [20/150], Train_Loss: 1.0762, Test_Loss: 1.0846, Test Accuracy: 0.74\n",
      "Epoch [21/150], Train_Loss: 1.0609, Test_Loss: 1.0771, Test Accuracy: 0.76\n",
      "Epoch [22/150], Train_Loss: 1.0291, Test_Loss: 1.0692, Test Accuracy: 0.78\n",
      "Epoch [23/150], Train_Loss: 1.1156, Test_Loss: 1.0603, Test Accuracy: 0.80\n",
      "Epoch [24/150], Train_Loss: 1.0210, Test_Loss: 1.0511, Test Accuracy: 0.80\n",
      "Epoch [25/150], Train_Loss: 1.0210, Test_Loss: 1.0410, Test Accuracy: 0.81\n",
      "Epoch [26/150], Train_Loss: 1.0688, Test_Loss: 1.0313, Test Accuracy: 0.81\n",
      "Epoch [27/150], Train_Loss: 0.9955, Test_Loss: 1.0213, Test Accuracy: 0.82\n",
      "Epoch [28/150], Train_Loss: 0.9848, Test_Loss: 1.0120, Test Accuracy: 0.83\n",
      "Epoch [29/150], Train_Loss: 0.9413, Test_Loss: 1.0030, Test Accuracy: 0.83\n",
      "Epoch [30/150], Train_Loss: 1.0017, Test_Loss: 0.9944, Test Accuracy: 0.83\n",
      "Epoch [31/150], Train_Loss: 1.0031, Test_Loss: 0.9858, Test Accuracy: 0.84\n",
      "Epoch [32/150], Train_Loss: 0.9548, Test_Loss: 0.9783, Test Accuracy: 0.84\n",
      "Epoch [33/150], Train_Loss: 0.9684, Test_Loss: 0.9706, Test Accuracy: 0.84\n",
      "Epoch [34/150], Train_Loss: 0.9458, Test_Loss: 0.9637, Test Accuracy: 0.84\n",
      "Epoch [35/150], Train_Loss: 0.9082, Test_Loss: 0.9568, Test Accuracy: 0.85\n",
      "Epoch [36/150], Train_Loss: 0.9875, Test_Loss: 0.9506, Test Accuracy: 0.86\n",
      "Epoch [37/150], Train_Loss: 0.9351, Test_Loss: 0.9446, Test Accuracy: 0.86\n",
      "Epoch [38/150], Train_Loss: 0.8717, Test_Loss: 0.9392, Test Accuracy: 0.86\n",
      "Epoch [39/150], Train_Loss: 0.9569, Test_Loss: 0.9340, Test Accuracy: 0.87\n",
      "Epoch [40/150], Train_Loss: 0.9277, Test_Loss: 0.9292, Test Accuracy: 0.87\n",
      "Epoch [41/150], Train_Loss: 0.9048, Test_Loss: 0.9243, Test Accuracy: 0.87\n",
      "Epoch [42/150], Train_Loss: 0.9204, Test_Loss: 0.9200, Test Accuracy: 0.87\n",
      "Epoch [43/150], Train_Loss: 0.9009, Test_Loss: 0.9163, Test Accuracy: 0.87\n",
      "Epoch [44/150], Train_Loss: 0.8923, Test_Loss: 0.9120, Test Accuracy: 0.88\n",
      "Epoch [45/150], Train_Loss: 0.9018, Test_Loss: 0.9088, Test Accuracy: 0.87\n",
      "Epoch [46/150], Train_Loss: 0.8657, Test_Loss: 0.9052, Test Accuracy: 0.88\n",
      "Epoch [47/150], Train_Loss: 0.8516, Test_Loss: 0.9018, Test Accuracy: 0.88\n",
      "Epoch [48/150], Train_Loss: 0.8595, Test_Loss: 0.8989, Test Accuracy: 0.89\n",
      "Epoch [49/150], Train_Loss: 0.8706, Test_Loss: 0.8961, Test Accuracy: 0.89\n",
      "Epoch [50/150], Train_Loss: 0.8205, Test_Loss: 0.8935, Test Accuracy: 0.90\n",
      "Epoch [51/150], Train_Loss: 0.8324, Test_Loss: 0.8909, Test Accuracy: 0.90\n",
      "Epoch [52/150], Train_Loss: 0.8899, Test_Loss: 0.8884, Test Accuracy: 0.90\n",
      "Epoch [53/150], Train_Loss: 0.9171, Test_Loss: 0.8861, Test Accuracy: 0.90\n",
      "Epoch [54/150], Train_Loss: 0.8317, Test_Loss: 0.8838, Test Accuracy: 0.90\n",
      "Epoch [55/150], Train_Loss: 0.8431, Test_Loss: 0.8821, Test Accuracy: 0.90\n",
      "Epoch [56/150], Train_Loss: 0.8489, Test_Loss: 0.8801, Test Accuracy: 0.90\n",
      "Epoch [57/150], Train_Loss: 0.9131, Test_Loss: 0.8781, Test Accuracy: 0.90\n",
      "Epoch [58/150], Train_Loss: 0.8816, Test_Loss: 0.8764, Test Accuracy: 0.90\n",
      "Epoch [59/150], Train_Loss: 0.8158, Test_Loss: 0.8748, Test Accuracy: 0.90\n",
      "Epoch [60/150], Train_Loss: 0.9008, Test_Loss: 0.8733, Test Accuracy: 0.90\n",
      "Epoch [61/150], Train_Loss: 0.9107, Test_Loss: 0.8719, Test Accuracy: 0.91\n",
      "Epoch [62/150], Train_Loss: 0.8148, Test_Loss: 0.8706, Test Accuracy: 0.91\n",
      "Epoch [63/150], Train_Loss: 0.9274, Test_Loss: 0.8693, Test Accuracy: 0.91\n",
      "Epoch [64/150], Train_Loss: 0.8867, Test_Loss: 0.8678, Test Accuracy: 0.91\n",
      "Epoch [65/150], Train_Loss: 0.8210, Test_Loss: 0.8665, Test Accuracy: 0.91\n",
      "Epoch [66/150], Train_Loss: 0.8638, Test_Loss: 0.8651, Test Accuracy: 0.91\n",
      "Epoch [67/150], Train_Loss: 0.8125, Test_Loss: 0.8641, Test Accuracy: 0.91\n",
      "Epoch [68/150], Train_Loss: 0.9071, Test_Loss: 0.8633, Test Accuracy: 0.91\n",
      "Epoch [69/150], Train_Loss: 0.8663, Test_Loss: 0.8618, Test Accuracy: 0.91\n",
      "Epoch [70/150], Train_Loss: 0.7896, Test_Loss: 0.8610, Test Accuracy: 0.91\n",
      "Epoch [71/150], Train_Loss: 0.8095, Test_Loss: 0.8600, Test Accuracy: 0.91\n",
      "Epoch [72/150], Train_Loss: 0.8321, Test_Loss: 0.8590, Test Accuracy: 0.91\n",
      "Epoch [73/150], Train_Loss: 0.8121, Test_Loss: 0.8582, Test Accuracy: 0.91\n",
      "Epoch [74/150], Train_Loss: 0.8527, Test_Loss: 0.8572, Test Accuracy: 0.91\n",
      "Epoch [75/150], Train_Loss: 0.8165, Test_Loss: 0.8563, Test Accuracy: 0.91\n",
      "Epoch [76/150], Train_Loss: 0.8179, Test_Loss: 0.8557, Test Accuracy: 0.91\n",
      "Epoch [77/150], Train_Loss: 0.9087, Test_Loss: 0.8548, Test Accuracy: 0.91\n",
      "Epoch [78/150], Train_Loss: 0.9847, Test_Loss: 0.8543, Test Accuracy: 0.91\n",
      "Epoch [79/150], Train_Loss: 0.7840, Test_Loss: 0.8532, Test Accuracy: 0.91\n",
      "Epoch [80/150], Train_Loss: 0.8712, Test_Loss: 0.8527, Test Accuracy: 0.91\n",
      "Epoch [81/150], Train_Loss: 0.8258, Test_Loss: 0.8519, Test Accuracy: 0.91\n",
      "Epoch [82/150], Train_Loss: 0.8610, Test_Loss: 0.8512, Test Accuracy: 0.91\n",
      "Epoch [83/150], Train_Loss: 0.7759, Test_Loss: 0.8508, Test Accuracy: 0.91\n",
      "Epoch [84/150], Train_Loss: 0.8705, Test_Loss: 0.8499, Test Accuracy: 0.91\n",
      "Epoch [85/150], Train_Loss: 0.8352, Test_Loss: 0.8492, Test Accuracy: 0.91\n",
      "Epoch [86/150], Train_Loss: 0.8360, Test_Loss: 0.8490, Test Accuracy: 0.91\n",
      "Epoch [87/150], Train_Loss: 0.7708, Test_Loss: 0.8483, Test Accuracy: 0.91\n",
      "Epoch [88/150], Train_Loss: 0.8621, Test_Loss: 0.8477, Test Accuracy: 0.91\n",
      "Epoch [89/150], Train_Loss: 0.8173, Test_Loss: 0.8470, Test Accuracy: 0.91\n",
      "Epoch [90/150], Train_Loss: 0.8252, Test_Loss: 0.8465, Test Accuracy: 0.91\n",
      "Epoch [91/150], Train_Loss: 0.8642, Test_Loss: 0.8461, Test Accuracy: 0.91\n",
      "Epoch [92/150], Train_Loss: 0.8317, Test_Loss: 0.8455, Test Accuracy: 0.91\n",
      "Epoch [93/150], Train_Loss: 0.8167, Test_Loss: 0.8452, Test Accuracy: 0.91\n",
      "Epoch [94/150], Train_Loss: 0.9595, Test_Loss: 0.8446, Test Accuracy: 0.91\n",
      "Epoch [95/150], Train_Loss: 0.9223, Test_Loss: 0.8441, Test Accuracy: 0.91\n",
      "Epoch [96/150], Train_Loss: 0.7885, Test_Loss: 0.8437, Test Accuracy: 0.91\n",
      "Epoch [97/150], Train_Loss: 0.7674, Test_Loss: 0.8431, Test Accuracy: 0.92\n",
      "Epoch [98/150], Train_Loss: 0.8311, Test_Loss: 0.8428, Test Accuracy: 0.92\n",
      "Epoch [99/150], Train_Loss: 0.8453, Test_Loss: 0.8423, Test Accuracy: 0.92\n",
      "Epoch [100/150], Train_Loss: 0.7679, Test_Loss: 0.8419, Test Accuracy: 0.92\n",
      "Epoch [101/150], Train_Loss: 0.8403, Test_Loss: 0.8415, Test Accuracy: 0.91\n",
      "Epoch [102/150], Train_Loss: 0.7775, Test_Loss: 0.8411, Test Accuracy: 0.92\n",
      "Epoch [103/150], Train_Loss: 0.7828, Test_Loss: 0.8408, Test Accuracy: 0.91\n",
      "Epoch [104/150], Train_Loss: 0.8857, Test_Loss: 0.8404, Test Accuracy: 0.91\n",
      "Epoch [105/150], Train_Loss: 0.7791, Test_Loss: 0.8397, Test Accuracy: 0.92\n",
      "Epoch [106/150], Train_Loss: 0.9201, Test_Loss: 0.8394, Test Accuracy: 0.92\n",
      "Epoch [107/150], Train_Loss: 0.7873, Test_Loss: 0.8392, Test Accuracy: 0.92\n",
      "Epoch [108/150], Train_Loss: 0.8348, Test_Loss: 0.8387, Test Accuracy: 0.91\n",
      "Epoch [109/150], Train_Loss: 0.8408, Test_Loss: 0.8386, Test Accuracy: 0.92\n",
      "Epoch [110/150], Train_Loss: 0.7709, Test_Loss: 0.8382, Test Accuracy: 0.92\n",
      "Epoch [111/150], Train_Loss: 0.8161, Test_Loss: 0.8378, Test Accuracy: 0.91\n",
      "Epoch [112/150], Train_Loss: 0.8176, Test_Loss: 0.8377, Test Accuracy: 0.91\n",
      "Epoch [113/150], Train_Loss: 0.8017, Test_Loss: 0.8373, Test Accuracy: 0.91\n",
      "Epoch [114/150], Train_Loss: 0.8336, Test_Loss: 0.8371, Test Accuracy: 0.91\n",
      "Epoch [115/150], Train_Loss: 0.8367, Test_Loss: 0.8367, Test Accuracy: 0.91\n",
      "Epoch [116/150], Train_Loss: 0.8385, Test_Loss: 0.8362, Test Accuracy: 0.92\n",
      "Epoch [117/150], Train_Loss: 0.8639, Test_Loss: 0.8360, Test Accuracy: 0.91\n",
      "Epoch [118/150], Train_Loss: 0.8182, Test_Loss: 0.8357, Test Accuracy: 0.91\n",
      "Epoch [119/150], Train_Loss: 0.8831, Test_Loss: 0.8354, Test Accuracy: 0.91\n",
      "Epoch [120/150], Train_Loss: 0.8457, Test_Loss: 0.8354, Test Accuracy: 0.91\n",
      "Epoch [121/150], Train_Loss: 0.8637, Test_Loss: 0.8350, Test Accuracy: 0.92\n",
      "Epoch [122/150], Train_Loss: 0.8779, Test_Loss: 0.8348, Test Accuracy: 0.92\n",
      "Epoch [123/150], Train_Loss: 0.7873, Test_Loss: 0.8345, Test Accuracy: 0.92\n",
      "Epoch [124/150], Train_Loss: 0.8234, Test_Loss: 0.8342, Test Accuracy: 0.92\n",
      "Epoch [125/150], Train_Loss: 0.9104, Test_Loss: 0.8340, Test Accuracy: 0.92\n",
      "Epoch [126/150], Train_Loss: 0.7765, Test_Loss: 0.8337, Test Accuracy: 0.92\n",
      "Epoch [127/150], Train_Loss: 0.7894, Test_Loss: 0.8335, Test Accuracy: 0.92\n",
      "Epoch [128/150], Train_Loss: 0.7999, Test_Loss: 0.8333, Test Accuracy: 0.92\n",
      "Epoch [129/150], Train_Loss: 0.8448, Test_Loss: 0.8329, Test Accuracy: 0.92\n",
      "Epoch [130/150], Train_Loss: 0.7970, Test_Loss: 0.8328, Test Accuracy: 0.92\n",
      "Epoch [131/150], Train_Loss: 0.8534, Test_Loss: 0.8325, Test Accuracy: 0.92\n",
      "Epoch [132/150], Train_Loss: 0.8547, Test_Loss: 0.8323, Test Accuracy: 0.92\n",
      "Epoch [133/150], Train_Loss: 0.7864, Test_Loss: 0.8320, Test Accuracy: 0.92\n",
      "Epoch [134/150], Train_Loss: 0.8781, Test_Loss: 0.8319, Test Accuracy: 0.92\n",
      "Epoch [135/150], Train_Loss: 0.7658, Test_Loss: 0.8318, Test Accuracy: 0.92\n",
      "Epoch [136/150], Train_Loss: 0.8751, Test_Loss: 0.8315, Test Accuracy: 0.92\n",
      "Epoch [137/150], Train_Loss: 0.8131, Test_Loss: 0.8313, Test Accuracy: 0.92\n",
      "Epoch [138/150], Train_Loss: 0.8675, Test_Loss: 0.8312, Test Accuracy: 0.92\n",
      "Epoch [139/150], Train_Loss: 0.7651, Test_Loss: 0.8309, Test Accuracy: 0.92\n",
      "Epoch [140/150], Train_Loss: 0.8916, Test_Loss: 0.8308, Test Accuracy: 0.92\n",
      "Epoch [141/150], Train_Loss: 0.7735, Test_Loss: 0.8306, Test Accuracy: 0.92\n",
      "Epoch [142/150], Train_Loss: 0.8836, Test_Loss: 0.8305, Test Accuracy: 0.92\n",
      "Epoch [143/150], Train_Loss: 0.8322, Test_Loss: 0.8303, Test Accuracy: 0.92\n",
      "Epoch [144/150], Train_Loss: 0.8459, Test_Loss: 0.8302, Test Accuracy: 0.92\n",
      "Epoch [145/150], Train_Loss: 0.8059, Test_Loss: 0.8298, Test Accuracy: 0.92\n",
      "Epoch [146/150], Train_Loss: 0.7903, Test_Loss: 0.8297, Test Accuracy: 0.92\n",
      "Epoch [147/150], Train_Loss: 0.7970, Test_Loss: 0.8296, Test Accuracy: 0.92\n",
      "Epoch [148/150], Train_Loss: 0.7576, Test_Loss: 0.8294, Test Accuracy: 0.92\n",
      "Epoch [149/150], Train_Loss: 0.7874, Test_Loss: 0.8292, Test Accuracy: 0.92\n",
      "Epoch [150/150], Train_Loss: 0.7757, Test_Loss: 0.8291, Test Accuracy: 0.92\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 150\n",
    "for epoch in range(num_epochs):\n",
    "    for inputs, targets in train_loader:\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets.float())\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    if (epoch+1) % 1 == 0:\n",
    "        with torch.no_grad():\n",
    "            outputs = model(X_test)\n",
    "            loss1 = criterion(outputs, y_test.float())\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            accuracy = (predicted == y_test_labels).sum().item() / y_test.size(0)\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Train_Loss: {loss.item():.4f}, Test_Loss: {loss1.item():.4f}, Test Accuracy: {accuracy:.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
